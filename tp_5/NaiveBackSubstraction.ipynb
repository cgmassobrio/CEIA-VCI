{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación del método de Naive para identificar objetos en movimiento\n",
    "\n",
    "**Índice**   \n",
    "1. [Registro de frame](#id1)\n",
    "2. [Funciones para implementación](#id2)\n",
    "3. [Pruebas por frame](#id3)\n",
    "4. [Segmentación de objetos en movimiento](#id4)\n",
    "5. [Comparativa con métodos de mezclas gaussianas](#id5)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy: 1.22.3\n",
      "openCV: 4.5.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Librerías principales\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Tipo de visualización\n",
    "%matplotlib inline\n",
    "\n",
    "# Versiones de librerías\n",
    "print(\"\".join(f\"{x[0]}: {x[1]}\\n\" for x in [\n",
    "    (\"Numpy\",np.__version__),\n",
    "    (\"openCV\",cv.__version__),\n",
    "    # (\"Matplotlib\",matplotlib.__version__),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la ruta para levantar los videos\n",
    "VD_DIR = r'.\\videos'\n",
    "VD_NAME = 'vtest.avi'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de frames<a name=\"id1\"></a>\n",
    "Se levanta el video que se empleará como test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apertura de archivo y creación del objeto \"capture\"\n",
    "#-------------------\n",
    "capture = cv.VideoCapture(os.path.join(VD_DIR, VD_NAME))\n",
    "\n",
    "if not capture.isOpened:\n",
    "    print('Falla al abrir el archivo: ' + VD_NAME)\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada frame se guarda en un array. Se tratará como un tensor. La primera dimensión da cuenta de la cantidad de frame que posee el video y fueron guardados de esta forma. Luego se extraen valores a emplear luego.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de frames guardados es correcta\n",
      "Cantidad de frames registrados:  795\n",
      "Verificación de dimensiones:  (795, 576, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "# Guardad de cada frame en array\n",
    "frames = []\n",
    "while True:\n",
    "    read, frame= capture.read()\n",
    "    if not read:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "frames = np.array(frames)\n",
    "\n",
    "# Frames por segundo\n",
    "fps = capture.get(cv.CAP_PROP_FPS)\n",
    "# Cantidad de frames guardados como array\n",
    "cant_frames = len(frames)\n",
    "\n",
    "# Verificación de lectura correcta\n",
    "if int(capture.get(cv.CAP_PROP_FRAME_COUNT)) == len(frames):\n",
    "    print(\"La cantidad de frames guardados es correcta\")\n",
    "    print(\"Cantidad de frames registrados: \", cant_frames)\n",
    "    print(\"Verificación de dimensiones: \", frames.shape)\n",
    "else:\n",
    "    print(\"No se ha guardado correctamente la cantidad de frames\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para implementación<a name=\"id2\"></a>\n",
    "La implementación se separó en dos partes. La primera es la construcción del background. Se calcula como la mediana de una muestra aleatoria de frames. El cálculo es por canal y por pixel. Luego se arma la máscara o _foreground_. Para ello se toma el frame que se está leyendo en el momento de la reproducción del video. Se la mejora aplicando en pasos:\n",
    "- Binarización tipo Otsu.\n",
    "- Filtro morfológico de cierre, ya que conviene cerrar la figura para que no haya agujeros (ceros) dentro de los objetos que afecten la transformada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_naive(input_frames, batch_size, seed, m_type='float32'):\n",
    "    '''\n",
    "    Función que devuelve la mediana, por canal, de un batch random formado por los frames de un video\n",
    "    Los valores son de tipo flotante por defecto.\n",
    "    - input_frames: array que contiene los frames de video a procesar.\n",
    "    - batch_size: tamaño del batch que contiene las muestras seleccionadas aleatoriamente sin reemplazo.\n",
    "    - seed: semilla para garantizar la repetitividad del proceso.\n",
    "    '''\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Cantidad de frames a procesar\n",
    "    cant_frames = len(input_frames)\n",
    "    # Generación de enteros random\n",
    "    idx = rng.choice(cant_frames, size=batch_size, replace=False, shuffle=False)\n",
    "    # Armado del batch. Se convierte a tipo flotante\n",
    "    batch = input_frames[idx,...].astype(m_type)\n",
    "\n",
    "    # Mediana del batch\n",
    "    return np.median(batch, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreground_naive(background, input_frame, thresh_value=0, max_val=255):\n",
    "    '''\n",
    "    Función que devuelve la máscara del objeto que se encuentra en movimiento. Incluye la binarizacion, empleando el método Otsu,\n",
    "    y la aplicación del filtro morfológico tipo cierre.\n",
    "    - background: tensor de 3 canales con la mediana del batch aleatorio de frames\n",
    "    - frame: frames de 3 canales con objetos a detectar.\n",
    "    - tresh_value: valor umbral del método OTSHU.\n",
    "    - max_val: valor máximo del método OTSHU.\n",
    "    '''\n",
    "    # Conversión del frame a float32\n",
    "    input_frame.astype('float32')\n",
    "    # resta\n",
    "    diff = background - input_frame\n",
    "    # normalizado\n",
    "    diff = cv.normalize(diff,None,0,255,cv.NORM_MINMAX).astype('uint8')\n",
    "    # pasaje a escala de grises\n",
    "    diff_gray = cv.cvtColor(diff,cv.COLOR_BGR2GRAY)\n",
    "    # binarización otsu\n",
    "    ret, thresh = cv.threshold(diff_gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    # Creamos un elemento estructurante y aplicamos operaciones morfologicas\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    # Filtro morfológico tipo cierre.\n",
    "    closing = cv.morphologyEx(thresh, cv.MORPH_CLOSE, kernel, iterations = 3)\n",
    "\n",
    "    return closing\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas por frame<a name=\"id3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selección de un frame del video: cambiar el número del primer índice\n",
    "# f_p = frames[100,...]\n",
    "# f_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # background\n",
    "# background_p = background_naive(frames, 50, 10)\n",
    "# # foreground\n",
    "# mask = foreground_naive(background_p, f_p)\n",
    "\n",
    "# plt.imshow(mask, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Implementación de máscara\n",
    "# indices = np.where(mask==255)\n",
    "# f_p[indices[0], indices[1], :] = [200, 0, 255]\n",
    "# plt.imshow(f_p)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de objetos en movimiento<a name=\"id4\"></a>\n",
    "A partir de las funciones presentadas, se segmentó el video, de acuerdo a la capacidad del algoritmo de detectar los objetos en movimiento. En este caso particular se trató de personas. Los parámetros a definir previamente son:\n",
    "- El tamaño del batch de frames.\n",
    "- El tiempo de actualización del background.\n",
    "- El valor de la semilla para garantizar la repetitibilidad de la prueba. \n",
    "  \n",
    "Con los valores predefinidos, la implementación muestra buenos resultados de segmentación. Solo si se debe mencionar que no logra incluir la mayoría de los rostros en la segmentación. Ocurre también que, dependiendo el color de ropa, tampoco segmenta a la vestimenta en particular. Sin embargo son casos marginales y la figura principal en movimiento es detectada por completo. \n",
    "\n",
    "En cuanto a performance al correr el algoritmo, presenta el inconveniente de la actualización del background. La reproducción se detiene hasta tanto no finalice dicho armado. \n",
    "\n",
    "![imagen 1](./images_result/frame_seg_1.png) ![imagen 2](./images_result/frame_seg_2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros a definir para la segmentación\n",
    "# -----------------------------------------\n",
    "batch_size = 50 # tamaño del batch de frames para armar el background\n",
    "t = 10.0 # tiempo de muestreo\n",
    "seed = 122 # semilla para garantizar la repetitibilidad de la prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la segmentación de objetos en movimiento por Naive\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Definición de las posiciones de frame donde se realiza la actualización del background\n",
    "update = np.arange(0, cant_frames, int(t*fps))\n",
    "update = np.append(update,1) # se agrega un 1 al final para que sean coherentes las dimensiones, no afecta a la implementación\n",
    "\n",
    "# Generación de semillas para garantizar la repetitibilidad de background generados aleatoriamente\n",
    "rng = np.random.default_rng(seed)\n",
    "seed_bg = rng.choice(4*len(update), size=len(update), replace=False, shuffle=False) \n",
    "\n",
    "# Contadores\n",
    "count=0\n",
    "s=0\n",
    "\n",
    "# Apertura de archivo y creación del objeto \"capture\"\n",
    "cap = cv.VideoCapture(os.path.join(VD_DIR, VD_NAME))\n",
    "if not cap.isOpened:\n",
    "    print('Falla al abrir el archivo: ' + VD_NAME)\n",
    "    exit(0)\n",
    "\n",
    "# Ciclo de segmentación\n",
    "while True:\n",
    "    r, f = cap.read()\n",
    "    if not r:\n",
    "        break\n",
    "    \n",
    "    # Actualización del background\n",
    "    if count == update[s]:\n",
    "        background = background_naive(frames, batch_size, seed_bg[s])\n",
    "        s+=1\n",
    "    # Contrucción del foreground\n",
    "    foreground = foreground_naive(background, f)\n",
    "    # Aplicación de la máscara al frame que se está leyendo\n",
    "    idx_fg = np.where(foreground==255)\n",
    "    f[idx_fg[0], idx_fg[1], :] = [200, 0, 255]\n",
    "    # Salida\n",
    "    cv.imshow('Foreground', foreground)\n",
    "    cv.imshow('Video segmentado', f)\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    # Se corre el video hasta que termine o se apriete escape\n",
    "    keyboard = cv.waitKey(30)\n",
    "    if keyboard == 'q' or keyboard == 27:\n",
    "        break\n",
    "    elif keyboard == ord('s'):\n",
    "        cv.imwrite('frame_seg.png',f)\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparativa con métodos de mezclas gaussianas<a name=\"id5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('opencv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c41c2bed6317fcc09dc6ef78ff357819e2ca7efa781e228fd0e70c6f824fa93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
